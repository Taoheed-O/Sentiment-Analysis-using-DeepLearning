{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560f0403",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4426dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00841079",
   "metadata": {},
   "source": [
    "#### Reading in the files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377dd57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oyeni\\AppData\\Local\\Temp\\ipykernel_8312\\696196850.py:1: DtypeWarning: Columns (4,5,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  auto_df = pd.read_csv(\"files/autos.csv\")\n"
     ]
    }
   ],
   "source": [
    "auto_df = pd.read_csv(\"files/autos.csv\")\n",
    "career_df = pd.read_csv(\"files/career.csv\")\n",
    "education_df = pd.read_csv(\"files/education.csv\")\n",
    "health_df = pd.read_csv(\"files/health.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943315ce",
   "metadata": {},
   "source": [
    "#### Labelling each according to the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df80dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df[\"label\"] = 'automobiles'\n",
    "career_df[\"label\"] = \"careers\"\n",
    "education_df[\"label\"] = \"education\"\n",
    "health_df[\"label\"] = \"health\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2368835",
   "metadata": {},
   "source": [
    "#### Making a copy of the data in case something goes wrong during the process of building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643ec0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df_1 = auto_df.copy()\n",
    "career_df_1 = career_df.copy()\n",
    "education_df_1 = education_df.copy()\n",
    "health_df_1 = health_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf8ebe",
   "metadata": {},
   "source": [
    "#### Extracting the needed labels from each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783bc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df_1 = auto_df_1[[\"Text\", \"label\"]]\n",
    "career_df_1 = career_df_1[[\"Text\", \"label\"]]\n",
    "education_df_1 = education_df_1[[\"Text\", \"label\"]]\n",
    "health_df_1 =health_df_1[[\"Text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc619751",
   "metadata": {},
   "source": [
    "#### Combining all the data together to form a single data to be used for both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "291dcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([auto_df_1, career_df_1, education_df_1, health_df_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0372d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 915854 entries, 0 to 155017\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Text    914337 non-null  object\n",
      " 1   label   915854 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 21.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(full_df.info())\n",
    "full_df.describe()\n",
    "full_df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79412806",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = full_df['Text']\n",
    "y = full_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98710e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d536e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = math.ceil((x_train.apply(lambda x: len(str(x).split())).mean()))+2\n",
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f339c",
   "metadata": {},
   "source": [
    "## Adding a token [PAD_TOKEN]  and an End Of Line token [EOS_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = \"<|pad|>\"\n",
    "EOS_TOKEN = \"<|endoftext|>\"\n",
    "\n",
    "# this will download and initialize the pre trained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",\n",
    "    pad_token=PAD_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    "    max_length=MAX_LENGTH,\n",
    "    is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4cdd52",
   "metadata": {},
   "source": [
    "## Adding the EOS at the end of each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [str(ex) + EOS_TOKEN for ex in x_train]\n",
    "x_test = [str(ex) + EOS_TOKEN for ex in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d0f9e",
   "metadata": {},
   "source": [
    "## Passing them on to the tokenizer and padding them to the max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in x_train]\n",
    "x_test_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)['input_ids'] for x in x_test]\n",
    "\n",
    "x_train_in = tf.squeeze(tf.convert_to_tensor(x_train_), axis=1)\n",
    "x_test_in = tf.squeeze(tf.convert_to_tensor(x_test_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdeaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in x_train]\n",
    "x_test_mask_ = [tokenizer(str(x), return_tensors='tf', max_length=MAX_LENGTH, truncation=True, pad_to_max_length=True, add_special_tokens=True)[\"attention_mask\"] for x in x_test]\n",
    "\n",
    "x_train_mask = tf.squeeze(tf.convert_to_tensor(x_train_mask_), axis=1)\n",
    "x_test_mask = tf.squeeze(tf.convert_to_tensor(x_test_mask_), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28473ce",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFGPT2Model.from_pretrained(\"gpt2\", use_cache=False,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id)\n",
    "model.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5004bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849823c",
   "metadata": {},
   "source": [
    "## Set the GPT2 pre-trained layers as non trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f792a4",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80ee46",
   "metadata": {},
   "source": [
    "# Building on GPT2. \n",
    "\n",
    "### The model takes in tokens and mask tensors. The outputs are the last hidden states of the last layer in the transformer. These are reduced using the mean over the sequence length, passed through 2 dense layers with dropout in between. \n",
    "\n",
    "### The output layer has three nodes, (softmax activation function for probabilities) for the four(4) classes we want to predict (Health, Education, Career and Automobile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(None,), dtype='int32')\n",
    "x = model(input, attention_mask=mask)\n",
    "x = tf.reduce_mean(x.last_hidden_state, axis=1)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54511398",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tf.keras.Model([input, mask], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5924d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1697679",
   "metadata": {},
   "source": [
    "# Model compilation\n",
    "\n",
    "### Compiling the model, choosing the learning rate, loss function and the metric to monitor and also a callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0005\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate)\n",
    "#loss=tf.keras.losses.BinaryCrossentropy()\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "clf.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"accuracy\", verbose=1, patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413b3c3",
   "metadata": {},
   "source": [
    "# The target tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6adc255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(value):\n",
    "    if value == 'automobiles':\n",
    "        return 0\n",
    "    if value == 'careers':\n",
    "        return 1\n",
    "    if value == 'education':\n",
    "        return 2\n",
    "    if value == \"health\":\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "843ca331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function above to the y_train and x_train\n",
    "y_train_ = y_train.map(map_sentiment)\n",
    "y_test_ = y_test.map(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_in = tf.constant(y_train_, dtype=tf.int32)\n",
    "y_test_in = tf.constant(y_test_, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84ab66",
   "metadata": {},
   "source": [
    "# Training the model and passing the number of epochs, batch_size and validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = clf.fit([X_train_in, X_train_mask], y_train_in, epochs=30, batch_size=32, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115314a3",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.evaluate([X_test_in, X_test_mask], y_test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fa7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.training = False\n",
    "y_pred = clf.predict([X_test_in, X_test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_out = tf.math.argmax(y_pred, axis=-1)\n",
    "y_pred_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b06c7",
   "metadata": {},
   "source": [
    "# Testing the model on the test dataset\n",
    "\n",
    "### Obtaining the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_in, y_pred_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2a2af",
   "metadata": {},
   "source": [
    "# Obtaining the CONFUSION MATRIX \n",
    "# Plotting it using a heatmap for better visualization of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix(y_test_in, y_pred_out))\n",
    "confusion_df.index = ['Actual -1', 'Actual 0', 'Actual 1']\n",
    "confusion_df.columns = ['Predicted -1', 'Predicted 0', 'Predicted 1']\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64191cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='d', linewidths=0.5) \n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
