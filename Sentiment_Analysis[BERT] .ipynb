{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2562f7f",
   "metadata": {},
   "source": [
    "# Installing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31943154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea46ddc",
   "metadata": {},
   "source": [
    "### checking for GPU or CPU\n",
    "#### GPU is generally more better for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b978db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9a917",
   "metadata": {},
   "source": [
    "#### Listing the files in our folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874dbb1",
   "metadata": {},
   "source": [
    "#### Reading in the files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108447a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv(\"files/autos.csv\")\n",
    "career_df = pd.read_csv(\"files/career.csv\")\n",
    "education_df = pd.read_csv(\"files/education.csv\")\n",
    "health_df = pd.read_csv(\"files/health.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ef8bb",
   "metadata": {},
   "source": [
    "#### Labelling each according to the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100631d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df[\"label\"] = 'automobiles'\n",
    "career_df[\"label\"] = \"careers\"\n",
    "education_df[\"label\"] = \"education\"\n",
    "health_df[\"label\"] = \"health\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc4e49",
   "metadata": {},
   "source": [
    "#### Making a copy of the data in case something goes wrong during the process of building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1186fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df_1 = auto_df.copy()\n",
    "career_df_1 = career_df.copy()\n",
    "education_df_1 = education_df.copy()\n",
    "health_df_1 = health_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6acbd1",
   "metadata": {},
   "source": [
    "#### Extracting the needed labels from each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df_1 = auto_df_1[[\"Text\", \"label\"]]\n",
    "career_df_1 = career_df_1[[\"Text\", \"label\"]]\n",
    "education_df_1 = education_df_1[[\"Text\", \"label\"]]\n",
    "health_df_1 =health_df_1[[\"Text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b89ef",
   "metadata": {},
   "source": [
    "#### Combining all the data together to form a single data to be used for both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9816669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([auto_df_1, career_df_1, education_df_1, health_df_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f00510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.info())\n",
    "full_df.describe()\n",
    "full_df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494ca44",
   "metadata": {},
   "source": [
    "#### Setting some variables to be used later on during the building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = list(set(full_df.label))\n",
    "label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(full_df['Text'], full_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa54673",
   "metadata": {},
   "source": [
    "# BASELINE MODEL\n",
    "\n",
    "### This is done so as to compare the accuracy of the model to the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8299c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "parameters = {'lr__C': [0.1, 0.5, 1, 2, 5, 10, 100, 1000]}\n",
    "\n",
    "best_classifier = GridSearchCV(pipeline, parameters, cv=5, verbose=1)\n",
    "best_classifier.fit(x_train, y_train)\n",
    "best_predictions = best_classifier.predict(test_texts)\n",
    "\n",
    "baseline_accuracy = np.mean(best_predictions == test_labels)\n",
    "print(\"Baseline accuracy:\", baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80870d",
   "metadata": {},
   "source": [
    "# __BERT__\n",
    "\n",
    "### BERT stands for Bidirectional Encoder Representations from Transformers. BERT models help machines understand and interpret the meaning of the text. It uses immediately preceding text to understand the context. It also checks the relationships of words within a sentence to give the actual meaning of words.\n",
    "\n",
    "### BERT will then convert a given sentence into an embedding vector. Embedding vector is used to represent the unique words in a given document. BERT ensures words with the same meaning will have a similar representation.\n",
    "\n",
    "### Machine learning does not work with text but works well with numbers. Thatâ€™s why BERT converts the input text into embedding vectors. The embedding vectors are numbers with which the model can easily work.\n",
    "\n",
    "### The BERT process undergoes two stages: Preprocessing and encoding.\n",
    "\n",
    "\n",
    "## __Preprocessing:__\n",
    "\n",
    "### Preprocessing is the first stage in BERT. This stage involves removing noise from our dataset. In this stage, BERT will clean the dataset. It also removes duplicate records from the dataset.\n",
    "\n",
    "### It will also format the dataset so that it can be easy to use during model training. This will increase the model performance.\n",
    "\n",
    "## __Encoding:__\n",
    "\n",
    "### Because machine learning does not really work well with texts, we need to convert the text into real numbers. This process is known as encoding. BERT will convert a given sentence into an embedding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf07ed",
   "metadata": {},
   "source": [
    "\n",
    "## Initializing a model\n",
    "\n",
    "### Google has made available a range of BERT models for us to experiment with. For English, there is a choice between three models: bert-large-uncased is the largest model that will likely give the best results. Its smaller siblings are bert-base-uncased and bert-base-cased, which are more practical to work with. For Chinese there is bert-base-chinese, and for the other languages we have bert-base-multilingual-uncased and bert-base-multilingual-cased.\n",
    "\n",
    "### Uncased means that the training text has been lowercased and accents have been stripped. This is usually better, unless you know that case information is important for your task, such as with Named Entity Recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e71771",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fcc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels = len(label2idx))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9cfdf",
   "metadata": {},
   "source": [
    "\n",
    "# DATA PREPARATION\n",
    "\n",
    "### Preparing the dataset for BERT. Every document will be presented as a _BertInputItem_ object, which contains all the information BERT needs:\n",
    "\n",
    "###    - A list of input ids. Take a look at the logging output to see what this means. Every text has been split up into subword units, which are shared between all the languages in the multilingual model. When a word appears frequently enough in a combined corpus of all languages, it is kept intact. If it is less frequent, it is split up into subword units that do occur frequently enough across all languages. This allows the model to process every text as a sequence of strings from a finite vocabulary of limited size. NB; The first [CLS] token. This token is added at the beginning of every document. The vector at the output of this token will be used by the BERT model for its sequence classification tasks: it serves as the input of the final, task-specific part of the neural network.\n",
    "\n",
    "###    - The input mask: This tells the model which parts of the input it should look at and which parts it should ignore. In our example, we have made sure that every text has a length of 100 tokens. This means that some texts will be cut off after 100 tokens, while others will have to be padded with extra tokens. In this latter case, these padding tokens will receive a mask value of 0, which means BERT should not take them into account for its classification task.\n",
    "###    - The segment_ids: The segment ids tell BERT which sequence every token belongs to.\n",
    "\n",
    "###    - The label id: the id of the label for this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bca182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MAX_SEQ_LENGTH=100\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "\n",
    "        \n",
    "    return input_items\n",
    "\n",
    "train_features = convert_examples_to_inputs(x_train, y_train, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n",
    "test_features = convert_examples_to_inputs(x_test, y_test, label2idx, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a402b90",
   "metadata": {},
   "source": [
    "# DATA LOADER INITIALIZATION\n",
    "\n",
    "### Initializing a data loader for the training and testing data. This data loader puts all the data in tensors and will allow for iteration over them during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832f94e",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation method\n",
    "\n",
    "### This method takes as input a model and a data loader with the data to be be evaluated. For each batch, it computes the output of the model and the loss. We use this output to compute the obtained precision, recall and F-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97037613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "                                          token_type_ids=segment_ids, labels=label_ids)\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e2ef3",
   "metadata": {},
   "source": [
    "\n",
    "# Training\n",
    "\n",
    "###    - Gradient Accumulation keep the batches small enough to fit into the memory of the GPU, while getting the advantages of using larger batch sizes. In practice, it means  summing the gradients of several batches, before performing a step of gradient descent.\n",
    "###    - The WarmupLinearScheduler will be used to vary the learning rate during the training process starting with a small learning rate, which increases linearly during the warmup stage. Afterwards it slowly decreases again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa6ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_GRAD_NORM = 5\n",
    "\n",
    "num_train_steps = int(len(train_dataloader.dataset) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(WARMUP_PROPORTION * num_train_steps)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ab78e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f03e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"/tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "PATIENCE = 2\n",
    "\n",
    "loss_history = []\n",
    "no_improvement = 0\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "    dev_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"Dev loss:\", dev_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or dev_loss < min(loss_history):\n",
    "        no_improvement = 0\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    if no_improvement >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    loss_history.append(dev_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b47b0",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation\n",
    "\n",
    "### Evaluating the model on some documents it has never seen. Loading the best model and have it predict the labels for all documents in the data. its precision, recall and F-score for the training and test set will be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels = len(target_names))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader)\n",
    "\n",
    "print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "\n",
    "bert_accuracy = np.mean(test_predicted == test_correct)\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a557891",
   "metadata": {},
   "source": [
    "# MODEL COMPARISON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\"accuracy\": {\"baseline\": baseline_accuracy, \"BERT\": bert_accuracy}})\n",
    "plt.rcParams['figure.figsize'] = (7,4)\n",
    "df.plot(kind=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
